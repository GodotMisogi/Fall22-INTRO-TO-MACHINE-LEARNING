{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course: Introduction to Machine Learning\n",
    "# Aissigment I\n",
    "### Instructor: Tan Bui-Thanh\n",
    "### TA: Hai Nguyen\n",
    "#### Due day ??? Sep 2022 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 1** (Linear regression for 2 linear features)\n",
    "\n",
    "Loading UCI Diabetes Dataset and considering the *BMI* and *BP* features, denoted as $x_1, x_2$, respectively. And, the diabetes risk score is the target denoted as $y$. We assuming the linear model has the form of\n",
    "\n",
    "$$ \\bar{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2.$$\n",
    "\n",
    "The mean square error loss function\n",
    "\n",
    "$$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^n(y^{(i)}-\\bar{y}^{(i)})^2$$\n",
    "where $n$ is the number of patients\n",
    "\n",
    "- (1.a) (+25 pt) Using the gradient descent algorithm to find the optimal $\\theta_1$ and $\\theta_2$.\n",
    "\n",
    "- (1.b) (+5 pt) Plotting the contour map of the loss function \n",
    "\n",
    "- (1.c) (+10 pt) Plotting the gradient descent direction lines on the contour map from two initial guess $(\\theta_1, \\theta_2) = (4,4)$ and $(\\theta_1, \\theta_2) = (0,0)$. (You should plot a point each 100 iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0. MSE: 0.027770\n",
      "[0 0]\n",
      "Iteration 100. MSE: 0.024186\n",
      "bmi    0.312557\n",
      "bp     0.213375\n",
      "dtype: float64\n",
      "Iteration 200. MSE: 0.021491\n",
      "bmi    0.587644\n",
      "bp     0.392295\n",
      "dtype: float64\n",
      "Iteration 300. MSE: 0.019460\n",
      "bmi    0.830233\n",
      "bp     0.541622\n",
      "dtype: float64\n",
      "Iteration 400. MSE: 0.017926\n",
      "bmi    1.044618\n",
      "bp     0.665551\n",
      "dtype: float64\n",
      "Iteration 500. MSE: 0.016762\n",
      "bmi    1.234510\n",
      "bp     0.767699\n",
      "dtype: float64\n",
      "Iteration 600. MSE: 0.015876\n",
      "bmi    1.403118\n",
      "bp     0.851184\n",
      "dtype: float64\n",
      "Iteration 700. MSE: 0.015199\n",
      "bmi    1.553217\n",
      "bp     0.918693\n",
      "dtype: float64\n",
      "Iteration 800. MSE: 0.014677\n",
      "bmi    1.687205\n",
      "bp     0.972544\n",
      "dtype: float64\n",
      "Iteration 900. MSE: 0.014272\n",
      "bmi    1.807156\n",
      "bp     1.014731\n",
      "dtype: float64\n",
      "Iteration 1000. MSE: 0.013956\n",
      "bmi    1.914866\n",
      "bp     1.046973\n",
      "dtype: float64\n",
      "Iteration 1100. MSE: 0.013706\n",
      "bmi    2.011887\n",
      "bp     1.070753\n",
      "dtype: float64\n",
      "Iteration 1200. MSE: 0.013507\n",
      "bmi    2.099564\n",
      "bp     1.087343\n",
      "dtype: float64\n",
      "Iteration 1300. MSE: 0.013346\n",
      "bmi    2.179060\n",
      "bp     1.097841\n",
      "dtype: float64\n",
      "Iteration 1400. MSE: 0.013215\n",
      "bmi    2.251384\n",
      "bp     1.103192\n",
      "dtype: float64\n",
      "Iteration 1500. MSE: 0.013106\n",
      "bmi    2.317408\n",
      "bp     1.104205\n",
      "dtype: float64\n",
      "Iteration 1600. MSE: 0.013014\n",
      "bmi    2.377890\n",
      "bp     1.101579\n",
      "dtype: float64\n",
      "Iteration 1700. MSE: 0.012936\n",
      "bmi    2.433487\n",
      "bp     1.095914\n",
      "dtype: float64\n",
      "Iteration 1800. MSE: 0.012869\n",
      "bmi    2.484767\n",
      "bp     1.087722\n",
      "dtype: float64\n",
      "Iteration 1900. MSE: 0.012810\n",
      "bmi    2.532227\n",
      "bp     1.077445\n",
      "dtype: float64\n",
      "Iteration 2000. MSE: 0.012757\n",
      "bmi    2.576295\n",
      "bp     1.065461\n",
      "dtype: float64\n",
      "Iteration 2100. MSE: 0.012711\n",
      "bmi    2.617347\n",
      "bp     1.052094\n",
      "dtype: float64\n",
      "Iteration 2200. MSE: 0.012669\n",
      "bmi    2.655706\n",
      "bp     1.037620\n",
      "dtype: float64\n",
      "Iteration 2300. MSE: 0.012631\n",
      "bmi    2.691656\n",
      "bp     1.022276\n",
      "dtype: float64\n",
      "Iteration 2400. MSE: 0.012596\n",
      "bmi    2.725444\n",
      "bp     1.006264\n",
      "dtype: float64\n",
      "Iteration 2500. MSE: 0.012563\n",
      "bmi    2.757287\n",
      "bp     0.989754\n",
      "dtype: float64\n",
      "Iteration 2600. MSE: 0.012534\n",
      "bmi    2.787372\n",
      "bp     0.972893\n",
      "dtype: float64\n",
      "Iteration 2700. MSE: 0.012506\n",
      "bmi    2.815865\n",
      "bp     0.955805\n",
      "dtype: float64\n",
      "Iteration 2800. MSE: 0.012480\n",
      "bmi    2.842909\n",
      "bp     0.938594\n",
      "dtype: float64\n",
      "Iteration 2900. MSE: 0.012456\n",
      "bmi    2.868633\n",
      "bp     0.921348\n",
      "dtype: float64\n",
      "Iteration 3000. MSE: 0.012434\n",
      "bmi    2.893147\n",
      "bp     0.904141\n",
      "dtype: float64\n",
      "Iteration 3100. MSE: 0.012413\n",
      "bmi    2.916551\n",
      "bp     0.887035\n",
      "dtype: float64\n",
      "Iteration 3200. MSE: 0.012393\n",
      "bmi    2.938930\n",
      "bp     0.870082\n",
      "dtype: float64\n",
      "Iteration 3300. MSE: 0.012375\n",
      "bmi    2.960363\n",
      "bp     0.853324\n",
      "dtype: float64\n",
      "Iteration 3400. MSE: 0.012357\n",
      "bmi    2.980916\n",
      "bp     0.836796\n",
      "dtype: float64\n",
      "Iteration 3500. MSE: 0.012341\n",
      "bmi    3.000652\n",
      "bp     0.820526\n",
      "dtype: float64\n",
      "Iteration 3600. MSE: 0.012326\n",
      "bmi    3.019623\n",
      "bp     0.804537\n",
      "dtype: float64\n",
      "Iteration 3700. MSE: 0.012311\n",
      "bmi    3.037878\n",
      "bp     0.788847\n",
      "dtype: float64\n",
      "Iteration 3800. MSE: 0.012298\n",
      "bmi    3.055461\n",
      "bp     0.773470\n",
      "dtype: float64\n",
      "Iteration 3900. MSE: 0.012285\n",
      "bmi    3.072411\n",
      "bp     0.758417\n",
      "dtype: float64\n",
      "Iteration 4000. MSE: 0.012273\n",
      "bmi    3.088762\n",
      "bp     0.743693\n",
      "dtype: float64\n",
      "Iteration 4100. MSE: 0.012261\n",
      "bmi    3.104548\n",
      "bp     0.729306\n",
      "dtype: float64\n",
      "Iteration 4200. MSE: 0.012250\n",
      "bmi    3.119796\n",
      "bp     0.715256\n",
      "dtype: float64\n",
      "Iteration 4300. MSE: 0.012240\n",
      "bmi    3.134534\n",
      "bp     0.701546\n",
      "dtype: float64\n",
      "Iteration 4400. MSE: 0.012231\n",
      "bmi    3.148784\n",
      "bp     0.688175\n",
      "dtype: float64\n",
      "Iteration 4500. MSE: 0.012222\n",
      "bmi    3.162571\n",
      "bp     0.675141\n",
      "dtype: float64\n",
      "Iteration 4600. MSE: 0.012213\n",
      "bmi    3.175913\n",
      "bp     0.662441\n",
      "dtype: float64\n",
      "Iteration 4700. MSE: 0.012205\n",
      "bmi    3.188831\n",
      "bp     0.650071\n",
      "dtype: float64\n",
      "Iteration 4800. MSE: 0.012198\n",
      "bmi    3.201341\n",
      "bp     0.638027\n",
      "dtype: float64\n",
      "Iteration 4900. MSE: 0.012191\n",
      "bmi    3.213460\n",
      "bp     0.626305\n",
      "dtype: float64\n",
      "Iteration 5000. MSE: 0.012184\n",
      "bmi    3.225203\n",
      "bp     0.614898\n",
      "dtype: float64\n",
      "Iteration 5100. MSE: 0.012178\n",
      "bmi    3.236584\n",
      "bp     0.603801\n",
      "dtype: float64\n",
      "Iteration 5200. MSE: 0.012172\n",
      "bmi    3.247617\n",
      "bp     0.593007\n",
      "dtype: float64\n",
      "Iteration 5300. MSE: 0.012166\n",
      "bmi    3.258314\n",
      "bp     0.582511\n",
      "dtype: float64\n",
      "Iteration 5400. MSE: 0.012161\n",
      "bmi    3.268687\n",
      "bp     0.572306\n",
      "dtype: float64\n",
      "Iteration 5500. MSE: 0.012156\n",
      "bmi    3.278748\n",
      "bp     0.562385\n",
      "dtype: float64\n",
      "Iteration 5600. MSE: 0.012151\n",
      "bmi    3.288506\n",
      "bp     0.552742\n",
      "dtype: float64\n",
      "Iteration 5700. MSE: 0.012147\n",
      "bmi    3.297973\n",
      "bp     0.543370\n",
      "dtype: float64\n",
      "Iteration 5800. MSE: 0.012142\n",
      "bmi    3.307158\n",
      "bp     0.534262\n",
      "dtype: float64\n",
      "Iteration 5900. MSE: 0.012139\n",
      "bmi    3.316070\n",
      "bp     0.525411\n",
      "dtype: float64\n",
      "Iteration 6000. MSE: 0.012135\n",
      "bmi    3.324718\n",
      "bp     0.516812\n",
      "dtype: float64\n",
      "Iteration 6100. MSE: 0.012131\n",
      "bmi    3.333110\n",
      "bp     0.508457\n",
      "dtype: float64\n",
      "Iteration 6200. MSE: 0.012128\n",
      "bmi    3.341254\n",
      "bp     0.500341\n",
      "dtype: float64\n",
      "Iteration 6300. MSE: 0.012125\n",
      "bmi    3.349159\n",
      "bp     0.492456\n",
      "dtype: float64\n",
      "Iteration 6400. MSE: 0.012122\n",
      "bmi    3.356831\n",
      "bp     0.484797\n",
      "dtype: float64\n",
      "Iteration 6500. MSE: 0.012119\n",
      "bmi    3.364278\n",
      "bp     0.477357\n",
      "dtype: float64\n",
      "Iteration 6600. MSE: 0.012117\n",
      "bmi    3.371507\n",
      "bp     0.470131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "\n",
    "def f(X, theta):\n",
    "    \"\"\"The linear model we are trying to fit.\n",
    "    \n",
    "    Parameters:\n",
    "    theta (np.array): d-dimensional vector of parameters\n",
    "    X (np.array): (n,d)-dimensional data matrix\n",
    "    \n",
    "    Returns:\n",
    "    y_pred (np.array): n-dimensional vector of predicted targets\n",
    "    \"\"\"\n",
    "    return X.dot(theta) + 0.4638\n",
    "\n",
    "def mean_squared_error(theta, X, y):\n",
    "    \"\"\"The cost function, J, describing the goodness of fit.\n",
    "    \n",
    "    Parameters:\n",
    "    theta (np.array): d-dimensional vector of parameters\n",
    "    X (np.array): (n,d)-dimensional design matrix\n",
    "    y (np.array): n-dimensional vector of targets\n",
    "    \"\"\"\n",
    "    return 0.5*np.mean((y-f(X, theta))**2)\n",
    "\n",
    "def mse_gradient(theta, X, y):\n",
    "    \"\"\"The gradient of the cost function.\n",
    "    \n",
    "    Parameters:\n",
    "    theta (np.array): d-dimensional vector of parameters\n",
    "    X (np.array): (n,d)-dimensional design matrix\n",
    "    y (np.array): n-dimensional vector of targets\n",
    "    \n",
    "    Returns:\n",
    "    grad (np.array): d-dimensional gradient of the MSE\n",
    "    \"\"\"\n",
    "    return np.mean((f(X, theta) - y) * X.T, axis=1)\n",
    "\n",
    "# Load the diabetes dataset\n",
    "X, y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
    "\n",
    "# # add an extra column of onens\n",
    "# X['one'] = 1\n",
    "\n",
    "# Collect 20 data points and only use bmi dimension\n",
    "X_train = X.iloc[-20:].loc[:, ['bmi', 'bp']]\n",
    "y_train = y.iloc[-20:] / 300\n",
    "\n",
    "threshold = 1e-6\n",
    "step_size = 4e-1\n",
    "theta, theta_prev = np.array([0,0]), np.array([1,1])\n",
    "opt_pts = [theta]\n",
    "opt_grads = []\n",
    "iter = 0\n",
    "\n",
    "while np.linalg.norm(theta - theta_prev) > threshold:\n",
    "    if iter % 100 == 0:\n",
    "        print('Iteration %d. MSE: %.6f' % (iter, mean_squared_error(theta, X_train, y_train)))\n",
    "        print(theta)\n",
    "    theta_prev = theta\n",
    "    gradient = mse_gradient(theta, X_train, y_train)\n",
    "    theta = theta_prev - step_size * gradient\n",
    "    opt_pts += [theta]\n",
    "    opt_grads += [gradient]\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bmi    1.308136\n",
       "bp     2.050266\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 2** (Linear regression for 2 nonlinear features, Multivariate Polynomial Regression)\n",
    "\n",
    "We still use the pairs of *BMI* and *BP* features ($x_1, x_2$). However, the linear model now is changed to\n",
    "\n",
    "$$ \\bar{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\theta_3 x_1 x_2 + \\theta_4 x_1^2 + \\theta_5 x_2^2$$\n",
    "\n",
    "The mean square error loss function\n",
    "\n",
    "$$J(\\theta)=\\frac{1}{2}\\sum_{i=1}^n(y^{(i)}-\\bar{y}^{(i)})^2$$\n",
    "where $n$ is the number of patients\n",
    "\n",
    "- (2.a) (+30 pt) Using the gradient descent algorithm to find the optimal $\\theta_i, i = 0, ..., 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 3** (Linear regression for 2 nonlinear features)\n",
    "\n",
    "Now instead of using gradient descent in question 2, you shall use the ordinary least squares approach to \n",
    "\n",
    "- (3.a) (+30 pt) derive the optimal solution $$\\theta^* = ( \\theta_0, \\theta_1,\\theta_2,\\theta_3,\\theta_4,\\theta_5)$$\n",
    "\n",
    "$\\text{Hint}^*:$ you can consider the matrix data are columns of \n",
    "\n",
    "$$ X = \\begin{bmatrix}\n",
    "- & \\bar{x}^{(1)} & - \\\\\n",
    "- & \\bar{x}^{(2)} & -  \\\\\n",
    "- & \\vdots  & - \\\\\n",
    "- & \\bar{x}^{(n)} & - \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $ \\bar{x} = (1, x_1, x_2,x_1x_2,x^2_1, x^2_2)$ is a row vector and $n$ is the number of patients\n",
    "\n",
    "- (3.b) (Bounus +5): Is your $\\theta^*$ is exactly the same as the question 2? why (Yes/No)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('skitlearn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21be62648f8e3839c3b4ce05d43053c0ccba5ecc90dec2be15f843391ed2568c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
