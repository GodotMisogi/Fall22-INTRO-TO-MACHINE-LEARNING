{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1><center>Course: Introduction to Machine Learning</center></h1>\n",
    "## <h1><center>Exam 1</center></h1>\n",
    "### <h1><center>Important NOTE: In order to get full grades, for every question, you need to provide the details of your work on how to get to a solution or the end of the proof</center></h1>\n",
    "#### <h1><center>Instructor: Tan Bui-Thanh</center></h1>\n",
    "#### <h1><center>TA: Hai Nguyen</center></h1>\n",
    "##### <h1><center>Duration 2 hours.</center></h1>\n",
    "##### <h1><center>Available: 7am, Friday, 23 September - 11pm, Sunday, 25 September.</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question 1**\n",
    "\n",
    "1. Explain what machine learning is? \n",
    "2. How many types of machine learning: describe and compare/contrast among them?\n",
    "\n",
    "### **Question 2**\n",
    "1. What does supervised learning consist of: describe and explain each of them in detail with example/demonstration. \n",
    "2. Describe and explain the gradient descent method. \n",
    "3. Let x be a vector of d features. Consider linear regression with nonlinear feature transform \\phi(x) with p features. Derive in detail the gradient using mean-squared loss function. Derive the normal equation.\n",
    "\n",
    "### **Question 3** (Weighted loss function)\n",
    "\n",
    "From assignment 1, we have learn the regression model for diabetes data, which predict the risk score for patients. Now, assume that we know some features are much more important than the others and we want our model to focus on that. To that end, we introduce a weight factor on that feature, for example,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{J}(\\theta) = \\frac{1}{2N} \\sum_{i = 1}^N \\left(  y^{(i)} - \\sum_{j}^{M} \\theta_j f_j \\,  \\, x_j^{(i)} \\right)^2,\n",
    "\\end{equation}\n",
    "\n",
    "where $f_j$ is the weighting factor for $j$ th feature, $N$ is number of data samples and $M$ number of features. The loss function (1) can be rewritten as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{J}(\\theta) = \\frac{1}{2N} \\left( \\Sigma X \\theta - Y \\right)^T \\left( \\Sigma X \\theta - Y \\right) + \\frac{\\lambda}{2N} \\left(\\theta^T \\theta \\right),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\Sigma_{ii} = f_i$ is the diagonal matrix.\n",
    "\n",
    "Derive the gradient and backtracking algorithm to determine the optimal $\\theta$.\n",
    "\n",
    "### **Question 4** (Training a linear map)\n",
    "\n",
    "An underlying linear map is defined as\n",
    "\n",
    "$$\n",
    "y = A u\n",
    "$$\n",
    "\n",
    "where \n",
    "$ A: \\mathcal{R}^n \\mapsto \\mathcal{R}^m $ and $ x \\in \\mathcal{R}^n, y \\in \\mathcal{R}^m .$ Aussming that you can generate as many training data points as you want, i.e., \n",
    "\n",
    "$$\n",
    "x^{(i)} \\sim  \\mathcal{N}(0,I).\n",
    "$$\n",
    "\n",
    "Then computing $$y^{(i)} = A x^{(i)}.$$\n",
    "\n",
    "Question: derive the strategy to train learn $A$ following steps\n",
    "1. Generating data\n",
    "2. Define the mean square loss function\n",
    "3. Assuming you have acess to autogradient tool (a well-known technique for backprogation in machine learning), write down the updating gradient descent scheme for learning the matrix $A$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "21be62648f8e3839c3b4ce05d43053c0ccba5ecc90dec2be15f843391ed2568c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
