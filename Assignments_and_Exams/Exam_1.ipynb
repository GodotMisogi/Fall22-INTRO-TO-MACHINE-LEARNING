{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1><center>Course: Introduction to Machine Learning</center></h1>\n",
    "## <h1><center>Exam 1</center></h1>\n",
    "### <h1><center>Important NOTE: In order to get full grades, for every question, you need to provide the details of your work on how to get to a solution or the end of the proof</center></h1>\n",
    "#### <h1><center>Instructor: Tan Bui-Thanh</center></h1>\n",
    "#### <h1><center>TA: Hai Nguyen</center></h1>\n",
    "##### <h1><center>Duration 2 hours.</center></h1>\n",
    "##### <h1><center>Available: 7am, Friday, 23 September - 11pm, Sunday, 25 September.</center></h1>\n",
    "\n",
    "\n",
    "### **Question 1**\n",
    "\n",
    "1. Explain what machine learning is? \n",
    "2. How many types of machine learning: describe and compare/contrast among them?\n",
    "3. What does supervised learning consist of: describe and explain each of them in detail with example/demonstration. \n",
    "5. Consider the following scenario: We have a set of photos of 10 people. We like to train a machine learning model to predict which person a new photo belong to. What are two types of machine learning techniques you would recommend in this case and describe how such machine learning techniques should help solve the problem.\n",
    "\n",
    "### **Question 2**\n",
    "1. What is generalization? What issues could prevent generalization in supervised learning? What are the ideas of overcoming these issues? \n",
    "2. Why do we need regularization in supervised learning? What does regularization do? Derive the normal equation with L2 regularization for the following setting: **Let x be a vector of d features. Consider linear regression with nonlinear feature transform $\\phi(x)$ with p features.**\n",
    "3. Look at the components of supervised learning and propose ideas to overcome the issues in question 1. without using regularization. State  pros and cons of regularization and your proposed approach and compare them.\n",
    "\n",
    "Solutions\n",
    "Q2. 2) Denote transformed non linear feature data set as\n",
    "$$ X = \\begin{bmatrix}\n",
    "- & \\phi({x})^{(1)} & - \\\\\n",
    "- & \\phi({x})^{(2)} & -  \\\\\n",
    "- & \\vdots  & - \\\\\n",
    "- & \\phi({x})^{(n)} & - \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "where $n$ is number of training data points. Then the loss function with L2 regularization is \n",
    "$$ J(\\theta) = \\frac{1}{2} (X \\theta - y)^\\top  (X \\theta - y) + \\frac{1}{2} \\lambda ||\\theta||_2^2 $$\n",
    "\n",
    "the normal equaiton is \n",
    "\n",
    "$$ \\theta^* = (X^\\top X + \\lambda I)^{-1}  X^\\top  y.$$\n",
    "\n",
    "\n",
    "\n",
    "### **Question 3** (Weighted loss function)\n",
    "\n",
    "From assignment 1, we have learn the regression model for diabetes data, which predicts the risk score for patients. Now, assume that we know some features are much more important than the others and we want our model to focus on that. To that end, we introduce a weight factor on that feature, for example,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{J}(\\theta) = \\frac{1}{2N} \\sum_{i = 1}^N \\left(  y^{(i)} - \\sum_{j}^{M} \\theta_j f_j \\,  \\, x_j^{(i)} \\right)^2 + \\frac{\\lambda}{2}||\\theta||^2_2,\n",
    "\\end{equation}\n",
    "\n",
    "where $f_j$ is the weighting factor for $j$ th feature, $N$ is number of data samples and $M$ number of features. \n",
    "\n",
    "Derive the gradient vector for the loss function and derive the normal equation to solve the above supervised learning problem.\n",
    "\n",
    "Solutions:\n",
    "\n",
    "The loss function can be rewritten as\n",
    "\n",
    "$$\n",
    "\\mathcal{J}(\\theta) = \\frac{1}{2N} \\left( \\Sigma X \\theta - Y \\right)^T \\left( \\Sigma X \\theta - Y \\right) + \\frac{\\lambda}{2N} \\left(\\theta^T \\theta \\right),\n",
    "$$\n",
    "\n",
    "where $\\Sigma_{ii} = f_i$ is the diagonal matrix.\n",
    "\n",
    "- Gradient of loss function:\n",
    "$$\n",
    "\\nabla_{\\theta} \\mathcal{J}(\\theta) = (X^\\top \\Sigma^\\top \\Sigma X + \\lambda I) \\theta - X^\\top \\Sigma^\\top y.\n",
    "$$\n",
    "\n",
    "\n",
    "- Normal equation:\n",
    "$$ \\theta^* = (X^\\top \\Sigma^\\top \\Sigma X + \\lambda I)^{-1}  X^\\top \\Sigma^\\top y.$$\n",
    "\n",
    "<!---\n",
    "### **Question 5** (Training a linear map)\n",
    "\n",
    "An underlying linear map is defined as\n",
    "\n",
    "$$\n",
    "y = A u\n",
    "$$\n",
    "\n",
    "where \n",
    "$ A: \\mathcal{R}^n \\mapsto \\mathcal{R}^m $ and $ x \\in \\mathcal{R}^n, y \\in \\mathcal{R}^m .$ Aussming that you can generate as many training data points as you want. In particular,\n",
    "\n",
    "$$\n",
    "x^{(i)} \\sim  \\mathcal{N}(0,I),\n",
    "$$\n",
    "then computing $$y^{(i)} = A x^{(i)}.$$\n",
    "\n",
    "Question: derive the strategy to train learn $A$ following steps\n",
    "1. Generating data\n",
    "2. Define the mean square loss function\n",
    "3. Assuming you have acess to autogradient tool (a well-known technique for backprogation in machine learning), write down the updating gradient descent scheme for learning the matrix $A$\n",
    "--->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "21be62648f8e3839c3b4ce05d43053c0ccba5ecc90dec2be15f843391ed2568c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
