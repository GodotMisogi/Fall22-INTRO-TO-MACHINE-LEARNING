{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h1><center>Course: Introduction to Machine Learning</center></h1>\n",
    "## <h1><center>Exam 2</center></h1>\n",
    "### <h1><center>Important NOTE: In order to get full grades, for every question, you need to provide the details of your work on how to get to a solution or the end of the proof</center></h1>\n",
    "#### <h1><center>Instructor: Tan Bui-Thanh</center></h1>\n",
    "#### <h1><center>TA: Hai Nguyen</center></h1>\n",
    "##### <h1><center>Duration 2 hours + 10 minutes.</center></h1>\n",
    "##### <h1><center>Available: 7am-11:59:00pm, Friday, 28 October.</center></h1>\n",
    "##### <h1><center>Available support: 10am-1:00:00pm, Friday, 28 October.</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 3** (Maximum Likelihood for Multiple outputs linear regression problem)\n",
    "In linear regression proble, we might encounter a case of multiple outputs, the model becomes\n",
    "\\left( y | x, W \\right)\n",
    "$$ p  \\left( y | x, W \\right) = \\prod_{j=1}^M \\mathcal{N} \\left( y_j | w_j^T x_i, \\sigma_j^2 \\right) $$\n",
    "\n",
    "1. Finding MLE solution $W$ from given training data $(\\phi(x)^{(i)}, y^{(i)})_{i=1}^N$.\n",
    "\n",
    "2. Given training data table,\n",
    "\n",
    "\\begin{array}{c | c}\n",
    "x & y\\\\\n",
    "\\hline\n",
    "0 & (-1,-1) \\\\\n",
    "0 & (-1,-2) \\\\\n",
    "0 & (-2,-1) \\\\\n",
    "1 & (1,1) \\\\\n",
    "1 & (1,2) \\\\\n",
    "1 & (2,1) \n",
    "\\end{array}\n",
    "\n",
    "and the transformed feature matrix is\n",
    "\n",
    "\\begin{align*}\n",
    "\\phi(0) = (1,0) \\\\\n",
    "\\phi(1) = (0,1) \n",
    "\\end{align*}\n",
    "\n",
    "Compute the $W$ by the formula obtained in part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question 4** (beta-binomial model):\n",
    "Flipping a coin problem is a example of Bernouli distribution (a special case of Binomial distribution). And, beta distribution is a \"conjugate prior\" for Binomial distribution. In the lecutre 5, we have got the mean of the posterior distribution in $(\\#\\,\\text{heads} + \\#\\,\\text{tails})$ trial:\n",
    "$$\\theta^*= \\frac{\\#\\,\\text{heads} + \\alpha}{\\#\\,\\text{heads}+\\#\\,\\text{tails} + \\alpha + \\beta}$$\n",
    "\n",
    "1. Finding the covariance of posterior distribution (Hint: convert to beta distribution). Discuss the relationship between the covariance and the number of samples.\n",
    "\n",
    "2. Finding the posterior preidctive distribution of getting one Head from one trial, i.e,\n",
    "$$p[x = 1 \\text{Heads}|\\mathcal{D}] = \\int_0^1 p[x = 1 \\text{Head}|\\theta] \\  p[\\theta|\\mathcal{D}] d\\theta$$\n",
    "\n",
    "Recall: beta distribution\n",
    "\n",
    "$$\n",
    "\\text{Beta}(x,|a,b) = \\frac{1}{B(a,b)} x^{a-1} (1-x)^{b-1},\n",
    "$$\n",
    "where $B(a,b)$ is a normalized constant. The mean and the variance are\n",
    "\n",
    "$$ \\text{mean} = \\frac{a}{a+b}, \\quad \\text{var} = \\frac{ab}{(a+b)^2(a+b+1)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "21be62648f8e3839c3b4ce05d43053c0ccba5ecc90dec2be15f843391ed2568c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
